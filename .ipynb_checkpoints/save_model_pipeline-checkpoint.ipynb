{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name):\n",
    "    '''\n",
    "    Permet de sauvegarder un model\n",
    "    '''\n",
    "    filename = f'./Streamlit/modeles/{model_name}.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "    print(f\"Modèle {model_name} sauvegardé avec succès\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_info_model(liste_model, liste_names, X_test, y_test):\n",
    "    '''\n",
    "    Permet de sauvegarder les infos suivantes pour chaque modèle de \"liste_model\" :\n",
    "     - les predictions\n",
    "     - les valeurs réelles\n",
    "     - la matrice de confusion\n",
    "     - le rapport de classification\n",
    "     - l'importance des variables si possible\n",
    "    '''\n",
    "    liste_save = []\n",
    "    FEATURES_NAMES = [name for name in X_train]\n",
    "    \n",
    "    for index_name, model in enumerate(liste_model):\n",
    "        predictions = model.predict(X_test)\n",
    "        matrice_confusion = confusion_matrix(Y_test, predictions)\n",
    "        rapport = classification_report(Y_test, predictions, output_dict=True)\n",
    "        model_importance = []\n",
    "\n",
    "        # Importance de la régression logistique\n",
    "        try:\n",
    "            coef = np.abs(model.coef_[0])\n",
    "            model_importance = pd.Series(coef, index=FEATURES_NAMES).sort_values(ascending=False)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            IMPORTANCE = model.feature_importances_\n",
    "            model_importance = pd.Series(IMPORTANCE, index=FEATURES_NAMES).sort_values(ascending=False)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "        # Liste qui contiendra les predictions, les valeurs réelles, la matrice de confusion, le rapport de classification et \n",
    "        # l'importance des variables si possible\n",
    "        liste_model = [liste_names[index_name], predictions, y_test, matrice_confusion, rapport, model_importance]\n",
    "        liste_save.append(liste_model)\n",
    "    \n",
    "    with open(\"./Streamlit/modeles/modeles_info\", \"wb\") as fp:\n",
    "        pickle.dump(liste_save, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'./depart_employes.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"target\"] = data[\"depart\"].astype('category')\n",
    "data.drop(\"depart\", axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=list(data.columns)[:-1]\n",
    "\n",
    "num_cols=list(data.columns)[:-3]\n",
    "cat_cols=list(data.columns)[-3:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilisation d'une pipeline pour faire le pre-traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('MinMaxScaler',MinMaxScaler()),\n",
    "    ('StandardScaler',StandardScaler()),\n",
    "    ('encoder_Service', LabelEncoder()),\n",
    "    ('encoder_niveau_salaire', LabelEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pipeline['MinMaxScaler'].fit_transform(data[num_cols])\n",
    "df=pd.DataFrame(df, columns=list(data[num_cols].columns))\n",
    "\n",
    "df[cat_cols]=data[cat_cols]\n",
    "df[\"target\"]=data[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df[\"target\"]\n",
    "X = df.drop(\"target\",axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, stratify = df.target, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardScaler = pipeline['StandardScaler'].fit_transform(X_train[num_cols])\n",
    "encoder_Service = pipeline['encoder_Service'].fit_transform(X_train['Service'])\n",
    "encoder_niveau_salaire = pipeline['encoder_niveau_salaire'].fit_transform(X_train['niveau_salaire'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vérifier que les transformers ont bien été entrainés\n",
    "Si les codes suivants produisent des erreurs, alors ils ne l'ont pas été"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline['encoder_Service'].classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline['MinMaxScaler'].scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enregistrement de la pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# joblib.dump(pipeline, f'./Streamlit/modeles/pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "\n",
    "model_KNN = KNeighborsClassifier(3)\n",
    "model_KNN.fit(X_train, Y_train)\n",
    "\n",
    "model_RL = LogisticRegression(random_state=0)\n",
    "model_RL.fit(X_train, Y_train)\n",
    "\n",
    "model_SVG = svm.SVC()\n",
    "model_SVG.fit(X_train, Y_train)\n",
    "\n",
    "model_TREE = tree.DecisionTreeClassifier()\n",
    "model_TREE.fit(X_train, Y_train)\n",
    "\n",
    "model_RF = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "model_RF.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde des infos des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=[model_KNN, model_RL, model_SVG, model_TREE, model_RF]\n",
    "model_names =[\"KNN_info\",\"RL_info\",\"SVG_info\",\"TREE_info\",\"RF_info\"]\n",
    "\n",
    "save_info_model(model, model_names, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, 'modele')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
